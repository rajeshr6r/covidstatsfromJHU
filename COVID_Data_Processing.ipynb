{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da6c4f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import requests\n",
    "import csv\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from io import StringIO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439019a3",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Designed to download Vaccination , Infection , Death and Recovery rate for COVID \n",
    "\n",
    "Vaccination Data comes from : https://github.com/owid/covid-19-data/tree/master/public/data/vaccinations \n",
    "TimeSerios for Infection,Death and Recovery comes from  : :https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_time_series\n",
    "\n",
    "These data sets have US and Global data . So possible duplications .\n",
    "\n",
    "These data sets are downloaded somewhere around 5:30 AM EST ( safer side to download them at about 0930 EST)\n",
    "\n",
    "We create a csv file for each url with a timestamp to denote the time at which the script got executed at our end \n",
    "\n",
    "Total files after script execution should be : 8\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39068222",
   "metadata": {},
   "outputs": [],
   "source": [
    "#url initialization\n",
    "vaccinations_url = \"https://raw.githubusercontent.com/owid/covid-19-data/master/public/data/vaccinations/vaccinations.csv\"\n",
    "vaccinations_by_age_group_url = \"https://raw.githubusercontent.com/owid/covid-19-data/master/public/data/vaccinations/vaccinations-by-age-group.csv\"\n",
    "vaccinations_by_manuf_url = \"https://raw.githubusercontent.com/owid/covid-19-data/master/public/data/vaccinations/vaccinations-by-manufacturer.csv\"\n",
    "covid19_timeseries_confirmed_us_url = \"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_US.csv\"\n",
    "covid19_timeseries_confirmed_global_url = \"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv\"\n",
    "covid19_time_series_covid19_deaths_US_url = \"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_US.csv\"\n",
    "covid19_time_series_covid19_deaths_global_url = \"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv\"\n",
    "covid19_time_series_covid19_recovered_global_url = \"https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_recovered_global.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c45b515c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to get data \n",
    "def process_url(url_to_be_processed,file_name_for_output):\n",
    "    try:\n",
    "        req = requests.get(url_to_be_processed)\n",
    "        url_content = req.content\n",
    "        csv_file = open(file_name_for_output, \"wb\")\n",
    "        csv_file.write(url_content)    \n",
    "        csv_file.close()\n",
    "\n",
    "        result = str(url_content, 'utf-8')\n",
    "        data = StringIO(result)\n",
    "        dataframe_variable = pd.read_csv(data)\n",
    "        return dataframe_variable\n",
    "    except Exception as e:\n",
    "        print(f\"Exception occured {str(e)}\")\n",
    "        return pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12d95c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#download and save the files and also load them into a dataframe\n",
    "\n",
    "df_vacc=process_url(vaccinations_url,'vaccinations.csv')\n",
    "df_vac_by_age=process_url(vaccinations_by_age_group_url,'vaccinations_by_age_group.csv')\n",
    "df_vacc_by_manuf=process_url(vaccinations_by_manuf_url,'vaccinations_by_manufacturer.csv')\n",
    "df_timeseries_confirmed_us=process_url(covid19_timeseries_confirmed_us_url,'covid19_timeseries_confirmed_US.csv')\n",
    "df_timeseries_confirmed_global=process_url(covid19_timeseries_confirmed_global_url,'covid19_timeseries_confirmed_global.csv')\n",
    "df_timeseries_death_US=process_url(covid19_time_series_covid19_deaths_US_url,'covid19_time_series_covid19_deaths_US.csv')\n",
    "df_timeseries_death_global=process_url(covid19_time_series_covid19_deaths_global_url,'covid19_time_series_covid19_deaths_global.csv')\n",
    "df_timeseries_recovered_global=process_url(covid19_time_series_covid19_recovered_global_url,'covid19_time_series_covid19_recovered_global.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a89d5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transpose the timeseries data to get the date wise data in rows from columns\n",
    "\n",
    "df_timeseries_confirmed_global_t=df_timeseries_confirmed_global.melt(['Province/State', 'Country/Region', 'Lat', 'Long'], var_name='ReportDate')\n",
    "df_timeseries_death_global_t=df_timeseries_death_global.melt(['Province/State', 'Country/Region', 'Lat', 'Long'], var_name='ReportDate')\n",
    "df_timeseries_recovered_global_t=df_timeseries_recovered_global.melt(['Province/State', 'Country/Region', 'Lat', 'Long'], var_name='ReportDate')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4a79cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleanup of column names post transpose\n",
    "\n",
    "df_timeseries_confirmed_global_t=df_timeseries_confirmed_global_t.rename(columns = {'value': 'Confirmed'}, inplace = False)\n",
    "df_timeseries_death_global_t=df_timeseries_death_global_t.rename(columns = {'value': 'Deaths'}, inplace = False)\n",
    "df_timeseries_recovered_global_t=df_timeseries_recovered_global_t.rename(columns = {'value': 'Recovered'}, inplace = False)\n",
    "\n",
    "df_timeseries_confirmed_global_t['ReportDate']=pd.to_datetime(df_timeseries_confirmed_global_t['ReportDate'])\n",
    "df_timeseries_death_global_t['ReportDate']=pd.to_datetime(df_timeseries_death_global_t['ReportDate'])\n",
    "df_timeseries_recovered_global_t['ReportDate']=pd.to_datetime(df_timeseries_recovered_global_t['ReportDate'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b33788fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a merged data frame to map confirmed / recovered / death cases side by side\n",
    "\n",
    "final_df = pd.merge(df_timeseries_confirmed_global_t, df_timeseries_death_global_t,  how='left', left_on=['Province/State', 'Country/Region', 'Lat', 'Long','ReportDate'], right_on = ['Province/State', 'Country/Region', 'Lat', 'Long','ReportDate'])\n",
    "final_df = pd.merge(final_df, df_timeseries_recovered_global_t,  how='left', left_on=['Province/State', 'Country/Region', 'Lat', 'Long','ReportDate'], right_on = ['Province/State', 'Country/Region', 'Lat', 'Long','ReportDate'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2ea2602",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort for obtaining difference between successive days to get day wise numbers .\n",
    "#Catch is that this works well with the data being sorted against the country and date . \n",
    "#However it blindly gets the difference without taking into consideration the difference in the country name.\n",
    "#So the first record for each country is not accurate . we should simply ignore the first record as a ugly fix.\n",
    "\n",
    "final_timeseries_df=final_df.sort_values(['Country/Region', 'ReportDate'], ascending=[True, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e3d50be",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_timeseries_output_df=pd.concat([final_timeseries_df,final_timeseries_df[['Confirmed', 'Deaths' , 'Recovered']].diff().rename({'Confirmed':'ConfirmedDiff', 'Deaths':'DeathDiff','Recovered':'RecoveredDiff'}, axis=1)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa32fdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop data for 22-01-2020 as this is not required . Refer to the previous step point number 4 for reasons.\n",
    "final_timeseries_output_df.drop(final_timeseries_output_df[final_timeseries_output_df['ReportDate'] == '2020-01-22T00:00:00.000000000'].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bab114de",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_timeseries_output_df.to_csv('final_timeseries_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3e6693b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vaccination Data Treatment\n",
    "#adding a dummy entry with 0 as starting counter to deal with countries that start with a number on day 1 \n",
    "for country in list(pd.unique(df_vacc['location'])):\n",
    "    df_vacc=df_vacc.append(\n",
    "        {\n",
    "            'location':country,\n",
    "            'iso_code':'',\n",
    "            'date':'2020-01-01',\n",
    "            'total_vaccinations':0,\n",
    "            'people_vaccinated':0,\n",
    "            'people_fully_vaccinated':0,\n",
    "            'daily_vaccinations_raw':0,\n",
    "            'daily_vaccinations':0,\n",
    "            'total_vaccinations_per_hundred':0,\n",
    "            'people_vaccinated_per_hundred':0,\n",
    "            'people_fully_vaccinated_per_hundred':0,\n",
    "            'daily_vaccinations_per_million':0\n",
    "        },\n",
    "        ignore_index=True\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c3bdd729",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vacc=df_vacc.reset_index(drop=True)\n",
    "df_vacc['date']=pd.to_datetime(df_vacc['date'])\n",
    "df_vacc=df_vacc.sort_values(['location', 'date'], ascending=[True, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "97b1ee97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill NANs with 0 \n",
    "#df_vacc=df_vacc.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1fd8c600",
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_vaccinations_df=pd.concat([df_vacc,df_vacc[['total_vaccinations', 'people_vaccinated' , 'people_fully_vaccinated']].diff().rename({'total_vaccinations':'total_vaccinations_diff', 'people_vaccinated':'people_vaccinated_diff','people_fully_vaccinated':'people_fully_vaccinated_diff'}, axis=1)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "581f0c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to treat country wise data and generate a clean data frame for day level calculations while populating missing values based on previously available data whenever possible for the same country\n",
    "def datacleanup(inputdataframe,countryname):\n",
    "    idf=inputdataframe\n",
    "    #first filter the dataframe to only have the relevant country . because the ffill conditions doesnt work great\n",
    "    idf=idf[idf['location']==countryname]\n",
    "    idf['total_vaccinations_new']=idf['total_vaccinations']\n",
    "    idf['people_vaccinated_new']=idf['people_vaccinated']\n",
    "    idf['people_fully_vaccinated_new']=idf['people_fully_vaccinated']\n",
    "    idf['total_vaccinations_new'].fillna(method='ffill',axis=0,inplace=True)\n",
    "    idf['people_vaccinated_new'].fillna(method='ffill',axis=0,inplace=True)\n",
    "    idf['people_fully_vaccinated_new'].fillna(method='ffill',axis=0,inplace=True)\n",
    "    #an additional step to avoid 0 and na problems\n",
    "    idf['total_vaccinations_new'].fillna(0,inplace=True)\n",
    "    idf['people_vaccinated_new'].fillna(0,inplace=True)\n",
    "    idf['people_fully_vaccinated_new'].fillna(0,inplace=True)\n",
    "    \n",
    "    #logic for calculating difference between successive days \n",
    "    odf=pd.concat([idf,idf[['total_vaccinations_new', 'people_vaccinated_new' , 'people_fully_vaccinated_new']].diff().rename({'total_vaccinations_new':'total_vaccinations_diff', 'people_vaccinated_new':'people_vaccinated_diff','people_fully_vaccinated_new':'people_fully_vaccinated_diff'}, axis=1)], axis=1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return odf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "987a40c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "countries=['United States','United Kingdom','India','Philippines']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c73f53ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vidhya/.local/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/home/vidhya/.local/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "/home/vidhya/.local/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/home/vidhya/.local/lib/python3.6/site-packages/pandas/core/series.py:4536: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  downcast=downcast,\n"
     ]
    }
   ],
   "source": [
    "finaldf=pd.DataFrame()\n",
    "for country in countries:\n",
    "    tempdf=datacleanup(df_vacc,country)\n",
    "    finaldf=finaldf.append(tempdf)\n",
    "    \n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ea748b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldf.to_csv('vaccinations_treated_final_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad5cada",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
